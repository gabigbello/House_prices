{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing train and test dataset\n",
    "test = pd.read_csv(\"test.csv\",sep=\",\")\n",
    "train = pd.read_csv(\"train.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#TRAIN DATASET\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train - description\n",
    "train.head(3) #initially we have a lot of null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train - shape\n",
    "train.shape #we have initially 1460 rows and 81 columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train - info\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Studying null values\n",
    "(train.isnull().sum()/train.shape[0]).sort_values(ascending=False).head(20) #finding % of null values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting all columns with more than 10% of null values\n",
    "remove = train.columns[(train.isnull().sum()/train.shape[0]) > 0.1]\n",
    "train = train.drop(remove,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking numeric columns\n",
    "numeric_columns = train.columns[train.dtypes != 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking categoric columns\n",
    "categoric_columns = train.columns[train.dtypes == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking and treating null values on numeric train base\n",
    "train_numeric = train.loc[:,numeric_columns]\n",
    "train_numeric.head()\n",
    "train_numeric.isnull().sum().sort_values(ascending=False) #Two columns with null values: GarageYrBlt and MasVnrArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GarageYrBlt\n",
    "top_garageyrblt = train_numeric.groupby(train_numeric['GarageYrBlt']).size().sort_values(ascending=False).head(5).tolist()\n",
    "#In order, we get: 2005.0,2006.0,2004.0,2003.0,2007.0. Will use these values to fill the null\n",
    "train_numeric['GarageYrBlt'].fillna(pd.Series(np.random.choice(top_garageyrblt,size=len(train_numeric.index))), inplace=True)\n",
    "#Checking if we still have null values\n",
    "train_numeric.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MasVnrArea\n",
    "top_masva = train_numeric.groupby(train_numeric['MasVnrArea']).size().sort_values(ascending=False).head(1)\n",
    "train_numeric['MasVnrArea'].fillna(top_masva, inplace=True)\n",
    "#Checking if we still have null values\n",
    "train_numeric.isnull().sum().sort_values(ascending=False) #No more null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking and treating null values on categoric train base\n",
    "train_categoric = train.loc[:,categoric_columns]\n",
    "train_categoric.head()\n",
    "train_categoric.isnull().sum().sort_values(ascending=False)\n",
    "'''\n",
    "Columns with null values:\n",
    "GarageCond       81\n",
    "GarageQual       81\n",
    "GarageFinish     81\n",
    "GarageType       81\n",
    "BsmtExposure     38\n",
    "BsmtFinType2     38\n",
    "BsmtCond         37\n",
    "BsmtFinType1     37\n",
    "BsmtQual         37\n",
    "Electrical        1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GarageCond\n",
    "garage_cond = train_categoric.groupby(train_categoric['GarageCond']).size().sort_values(ascending=False).head(5)\n",
    "#Since we have a huge difference between 'TA' and other values in this column, we will replace null values for 'TA'\n",
    "train_categoric['GarageCond'].fillna('TA',inplace=True)\n",
    "#Checking if we still have null values on GarageCond\n",
    "train_categoric.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GarageQual, GarageFinish, GarageType\n",
    "garage_qual = train_categoric.groupby(train_categoric['GarageQual']).size().sort_values(ascending=False).head(5) #same case as GarageCond\n",
    "garage_finish = train_categoric.groupby(train_categoric['GarageFinish']).size().sort_values(ascending=False).head(5)\n",
    "garage_type = train_categoric.groupby(train_categoric['GarageType']).size().sort_values(ascending=False).head(5)\n",
    "\n",
    "#Garage qual is the same case as GarageCond -> Fill with TA\n",
    "train_categoric['GarageQual'].fillna('TA',inplace=True)\n",
    "#For GarageFinish, we have not much difference between the data, so we will random fill the null values\n",
    "train_categoric['GarageFinish'].fillna(pd.Series(np.random.choice(garage_finish.tolist(),size=len(train_categoric.index))), inplace=True)\n",
    "#For GarageType, we have a huge difference between \"Attchd\" and other values, so we can fill the null values with this item\n",
    "train_categoric['GarageType'].fillna('Attchd',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BsmtExposure, BsmtFinType2, BsmtCond, BsmtQual, BsmtFinType1\n",
    "bsmt_exposure = train_categoric.groupby(train_categoric['BsmtExposure']).size().sort_values(ascending=False).head(5)\n",
    "#Replacing for No, since it's an outstanding class in the data\n",
    "train_categoric['BsmtExposure'].fillna('No',inplace=True)\n",
    "bsmt_fin2 = train_categoric.groupby(train_categoric['BsmtFinType2']).size().sort_values(ascending=False).head(5)\n",
    "#Replacing for Unf, since it's an outstanding class in the data\n",
    "train_categoric['BsmtFinType2'].fillna('Unf',inplace=True)\n",
    "bsmt_fin1 = train_categoric.groupby(train_categoric['BsmtFinType1']).size().sort_values(ascending=False).head(2)\n",
    "#Random fill with top 2 values (430 and 418)\n",
    "train_categoric['BsmtFinType1'].fillna(pd.Series(np.random.choice(bsmt_fin1.tolist(),size=len(train_categoric.index))), inplace=True)\n",
    "bsmt_cond = train_categoric.groupby(train_categoric['BsmtCond']).size().sort_values(ascending=False).head(5)\n",
    "#Filling null with TA, since it's the outstanding value\n",
    "train_categoric['BsmtCond'].fillna('TA',inplace=True)\n",
    "bsmt_qual = train_categoric.groupby(train_categoric['BsmtQual']).size().sort_values(ascending=False).head(5)\n",
    "#Random filling null with top 2 values (649 and 618)\n",
    "train_categoric['BsmtQual'].fillna(pd.Series(np.random.choice(bsmt_qual.tolist(),size=len(train_categoric.index))), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Electrical\n",
    "electrical = train_categoric.groupby(train_categoric['Electrical']).size().sort_values(ascending=False).head(5)\n",
    "#Fill with 'Sbrkr' which is the most outstanding value\n",
    "train_categoric['Electrical'].fillna('SBrkr',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting our final train_dataset by combining both numeric and categoric data\n",
    "train_dataset = pd.concat([train_numeric,train_categoric],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#TEST DATASET\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we will do the same thing we've done above to check for null values and understand our columns\n",
    "test.head(3)\n",
    "test.shape #1459 rows and 80 columns (no 'Sales price' column, which is what we want to predict)\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing all columns that have more than 10% of null values\n",
    "(test.isnull().sum()/test.shape[0]).sort_values(ascending=False).head(20)\n",
    "remove_test = test.columns[(test.isnull().sum()/test.shape[0]) > 0.1]\n",
    "test = test.drop(remove_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_tst = test.columns[test.dtypes != 'object']\n",
    "categoric_tst = test.columns[test.dtypes == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treating numeric values\n",
    "test_numeric = test.loc[:,numeric_tst]\n",
    "test_numeric.head(5)\n",
    "test_numeric.isnull().sum().sort_values(ascending=False).head(10) #10 columns with null values\n",
    "'''\n",
    "GarageYrBlt     78\n",
    "MasVnrArea      15\n",
    "BsmtHalfBath     2\n",
    "BsmtFullBath     2\n",
    "BsmtUnfSF        1\n",
    "GarageCars       1\n",
    "GarageArea       1\n",
    "BsmtFinSF1       1\n",
    "BsmtFinSF2       1\n",
    "TotalBsmtSF      1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping columns\n",
    "garage_yrblt = test_numeric.groupby(test_numeric['GarageYrBlt']).size().sort_values(ascending=False).head(5)\n",
    "masvnrarea = test_numeric.groupby(test_numeric['MasVnrArea']).size().sort_values(ascending=False).head(5)\n",
    "bsmthalfbath = test_numeric.groupby(test_numeric['BsmtHalfBath']).size().sort_values(ascending=False).head(5)\n",
    "bsmtfullbath = test_numeric.groupby(test_numeric['BsmtFullBath']).size().sort_values(ascending=False).head(5)\n",
    "bsmtunfsf = test_numeric.groupby(test_numeric['BsmtUnfSF']).size().sort_values(ascending=False).head(5)\n",
    "garagecars = test_numeric.groupby(test_numeric['GarageCars']).size().sort_values(ascending=False).head(5)\n",
    "garagearea = test_numeric.groupby(test_numeric['GarageArea']).size().sort_values(ascending=False).head(5)\n",
    "bsmtfinsf1 = test_numeric.groupby(test_numeric['BsmtFinSF1']).size().sort_values(ascending=False).head(5)\n",
    "bsmtfinsf2 = test_numeric.groupby(test_numeric['BsmtFinSF2']).size().sort_values(ascending=False).head(5)\n",
    "totalbsmtsf = test_numeric.groupby(test_numeric['TotalBsmtSF']).size().sort_values(ascending=False).head(2)\n",
    "\n",
    "#Garage_yrblt - Random fill with top 5 values\n",
    "test_numeric['GarageYrBlt'].fillna(pd.Series(np.random.choice(garage_yrblt.tolist(),size=len(test_numeric.index))), inplace=True)\n",
    "#MasVnrArea - Fill with 0.0\n",
    "test_numeric['MasVnrArea'].fillna('0.0',inplace=True)\n",
    "#BmstHalfBath - Fill with 0.0\n",
    "test_numeric['BsmtHalfBath'].fillna('0.0',inplace=True)\n",
    "#Bsmtfullbath - fill with 0.0\n",
    "test_numeric['BsmtFullBath'].fillna('0.0',inplace=True)\n",
    "#Bsmtunfsf - fill with 0.0\n",
    "test_numeric['BsmtUnfSF'].fillna('0.0',inplace=True)\n",
    "#Garagecars - fill with '2.0'\n",
    "test_numeric['GarageCars'].fillna('2.0',inplace=True)\n",
    "#GarageArea - randomic fill among top 5 values\n",
    "test_numeric['GarageArea'].fillna(pd.Series(np.random.choice(garagearea.tolist(),size=len(test_numeric.index))), inplace=True)\n",
    "#BsmtfinsF1 (Fill with '0.0') and BsmtfinsF2 (Fill with '0.0')\n",
    "test_numeric['BsmtFinSF1'].fillna('0.0',inplace=True)\n",
    "test_numeric['BsmtFinSF2'].fillna('0.0',inplace=True)\n",
    "#TotalBsmtSF - Randomic fill among top 2\n",
    "test_numeric['TotalBsmtSF'].fillna(pd.Series(np.random.choice(totalbsmtsf.tolist(),size=len(test_numeric.index))),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_categoric = test.loc[:,categoric_tst]\n",
    "test_categoric.head(5)\n",
    "test_categoric.isnull().sum().sort_values(ascending=False).head(16) #16 columns with null values\n",
    "'''\n",
    "GarageCond      78\n",
    "GarageQual      78\n",
    "GarageFinish    78\n",
    "GarageType      76\n",
    "BsmtCond        45\n",
    "BsmtExposure    44\n",
    "BsmtQual        44\n",
    "BsmtFinType1    42\n",
    "BsmtFinType2    42\n",
    "MSZoning         4\n",
    "Functional       2\n",
    "Utilities        2\n",
    "Exterior1st      1\n",
    "Exterior2nd      1\n",
    "SaleType         1\n",
    "KitchenQual      1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GarageCond      78\n",
    "tst_garagecond = test_categoric.groupby(test_categoric['GarageCond']).size().sort_values(ascending=False).head(5) \n",
    "test_categoric['GarageCond'].fillna('TA',inplace=True)\n",
    "#GarageQual      78\n",
    "tst_garagequal = test_categoric.groupby(test_categoric['GarageQual']).size().sort_values(ascending=False).head(5)\n",
    "test_categoric['GarageQual'].fillna('TA',inplace=True)\n",
    "#GarageFinish    78\n",
    "tst_garagefinish = test_categoric.groupby(test_categoric['GarageFinish']).size().sort_values(ascending=False).head(5)\n",
    "test_categoric['GarageFinish'].fillna('Unf',inplace=True)\n",
    "#GarageType      76\n",
    "tst_garagetype = test_categoric.groupby(test_categoric['GarageType']).size().sort_values(ascending=False).head(5)\n",
    "test_categoric['GarageType'].fillna('Attchd',inplace=True)\n",
    "#BsmtCond        45\n",
    "tst_bsmtcond = test_categoric.groupby(test_categoric['BsmtCond']).size().sort_values(ascending=False).head(5)\n",
    "test_categoric['BsmtCond'].fillna('TA',inplace=True)\n",
    "#BsmtExposure    44\n",
    "tst_bsmtexposure = test_categoric.groupby(test_categoric['BsmtExposure']).size().sort_values(ascending=False).head(5)\n",
    "test_categoric['BsmtExposure'].fillna('No',inplace=True)\n",
    "#BsmtQual        44\n",
    "tst_bsmtqual = test_categoric.groupby(test_categoric['BsmtQual']).size().sort_values(ascending=False).head(2)\n",
    "test_categoric['BsmtQual'].fillna(pd.Series(np.random.choice((tst_bsmtqual.tolist()),size=len(test_categoric.index))),inplace=True)\n",
    "#BsmtFinType1    42\n",
    "tst_bsmtfintype1 = test_categoric.groupby(test_categoric['BsmtFinType1']).size().sort_values(ascending=False).head(2)\n",
    "test_categoric['BsmtFinType1'].fillna(pd.Series(np.random.choice((tst_bsmtfintype1.tolist()),size=len(test_categoric.index))),inplace=True)\n",
    "#BsmtFinType2    42\n",
    "tst_bsmtfintype2 = test_categoric.groupby(test_categoric['BsmtFinType2']).size().sort_values(ascending=False).head(5)\n",
    "test_categoric['BsmtFinType2'].fillna('Unf',inplace=True)\n",
    "#MSZoning         4\n",
    "tst_mszoning = test_categoric.groupby(test_categoric['MSZoning']).size().sort_values(ascending=False).head(5)\n",
    "test_categoric['MSZoning'].fillna('RL',inplace=True)\n",
    "#Functional       2\n",
    "tst_functional = test_categoric.groupby(test_categoric['Functional']).size().sort_values(ascending=False).head(5)\n",
    "test_categoric['Functional'].fillna('Typ',inplace=True)\n",
    "#Utilities        2\n",
    "tst_utilities = test_categoric.groupby(test_categoric['Utilities']).size().sort_values(ascending=False).head(5) #Only AllPub\n",
    "test_categoric['Utilities'].fillna('AllPub',inplace=True)\n",
    "#Exterior1st      1\n",
    "tst_exterior1st = test_categoric.groupby(test_categoric['Exterior1st']).size().sort_values(ascending=False).head(5)\n",
    "test_categoric['Exterior1st'].fillna('VinylSd',inplace=True)\n",
    "#Exterior2nd      1\n",
    "tst_exterior2nd = test_categoric.groupby(test_categoric['Exterior2nd']).size().sort_values(ascending=False).head(5)\n",
    "test_categoric['Exterior2nd'].fillna('VinylSd',inplace=True)\n",
    "#SaleType         1\n",
    "tst_saletype = test_categoric.groupby(test_categoric['SaleType']).size().sort_values(ascending=False).head(5)\n",
    "test_categoric['SaleType'].fillna('WD',inplace=True)\n",
    "#KitchenQual      1\n",
    "tst_kitchenqual = test_categoric.groupby(test_categoric['KitchenQual']).size().sort_values(ascending=False).head(5)\n",
    "test_categoric['KitchenQual'].fillna('TA',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting our final test dataset with no null values\n",
    "test_dataset = pd.concat([test_numeric,test_categoric],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing train and test datasets\n",
    "columns_in_train_not_in_test = (set(train_dataset.columns)) - (set(test_dataset.columns))\n",
    "columns_in_test_not_in_train = (set(test_dataset.columns)) - (set(train_dataset.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#ORGANIZING DATASETS + CLEANING SOME COLUMNS\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we will clean our database by removing some columns that may not add important info to our study. \n",
    "\n",
    "columns_to_remove = ['LandContour','LotConfig','YearRemodAdd','RoofStyle','Exterior2nd',\n",
    "                     'MasVnrArea','ExterCond','BsmtQual','BsmtExposure','BsmtFinSF1','BsmtFinType1','BsmtFinType2','BsmtFinSF2','BsmtUnfSF',\n",
    "                     'HeatingQC','Electrical','Functional','GarageYrBlt','GarageFinish','GarageCars','GarageCond','3SsnPorch',\n",
    "                     'ScreenPorch','MoSold','YrSold']\n",
    "\n",
    "'''['Lot Frontage','Alley','LandContour','LotConfig','Land Slope','Condition 2','House Style','YearRemodAdd','RoofStyle','Exterior2nd',\n",
    "                     'MasVnrArea','ExterCond','BsmtQual','BsmtExposure','BsmtFinSF1','BsmtFinType1','BsmtFinType2','BsmtFinSF2','BsmtUnfSF',\n",
    "                     'HeatingQC','Electrical','Functional','FireplaceQu','GarageYrBlt','GarageFinish','GarageCars','GarageCond','3SsnPorch',\n",
    "                     'ScreenPorch','MiscFeature','MoSold','YrSold']'''\n",
    "\n",
    "#['Lot Frontage', 'Alley', 'Land Slope', 'Condition 2', 'House Style', 'FireplaceQu', 'MiscFeature'] \n",
    "\n",
    "train_final1 = train_dataset.drop(columns_to_remove,axis=1) #This leaves us with 49 columns to treat\n",
    "train_final1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treating the rest of the columns we have on our database\n",
    "\n",
    "#MSZoning - Only letting the first letter of the values (this way we will make RH, RL, RP and RM into one (Residential))\n",
    "group_msz = train_final1.groupby(train_final1['MSZoning']).size()\n",
    "train_final1['MSZoning'] = train_final1['MSZoning'].str[0]\n",
    "\n",
    "#LotShape - Transform data to keep only the first letter (R for Regular and I for Irregular)\n",
    "group_ls = train_final1.groupby(train_final1['LotShape']).size()\n",
    "train_final1['LotShape'] = train_final1['LotShape'].str[0]\n",
    "\n",
    "#Create column (Overall) with the sum of OverallQual and OverallCond\n",
    "#train_final1['Overall'] = train_final1['OverallCond'] + train_final1['OverallQual']\n",
    "#group_ov = train_final1.groupby(train_final1['Overall']).size()\n",
    "#train_final1 = train_final1.drop(columns=['OverallCond','OverallQual'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1stFlrSF and 2ndFlrSF - Put it into groups of data\n",
    "#--------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#1stFlrSF\n",
    "#--------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#Using kmeans to understand what is the better way to divide the groups\n",
    "fflrsf = train_final1['1stFlrSF'].values.reshape(-1,1)\n",
    "sse = []\n",
    "for i in range(1,11):\n",
    "    kmeans = KMeans(n_clusters=i)\n",
    "    kmeans.fit(fflrsf)\n",
    "    sse.append(kmeans.inertia_) #Lower SSE values indicate more compact and well-defined clusters.\n",
    "\n",
    "\"\"\" plt.plot(range(1,11),sse,marker='x')\n",
    "plt.xlabel('Clusters nmb')\n",
    "plt.ylabel('Inertia sum') #sum of the distances to the center\n",
    "plt.title('Kmeans for 1stFlrSF')\n",
    "plt.show() \"\"\"\n",
    "\n",
    "#3 groups is our optimal number of clusters for 1stFlrSF\n",
    "\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(fflrsf)\n",
    "clusters = kmeans.predict(fflrsf)\n",
    "df_fstflrsf = pd.DataFrame({'Value':train_final1['1stFlrSF'],'Cluster':clusters})\n",
    "\n",
    "train_final1['1stFlrSF Cluster'] = clusters\n",
    "train_final1.drop(columns=['1stFlrSF'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#2ndFlrSF\n",
    "#--------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "sflrsf = train_final1['2ndFlrSF'].values.reshape(-1,1)\n",
    "sse=[]\n",
    "for i in range(1,11):\n",
    "    kmeans=KMeans(n_clusters=i)\n",
    "    kmeans.fit(sflrsf)\n",
    "    sse.append(kmeans.inertia_)\n",
    "\n",
    "\"\"\" plt.plot(range(1,11),sse,marker='x')\n",
    "plt.xlabel('Clusters nmb')\n",
    "plt.ylabel('Inertia sum')\n",
    "plt.title('Kmeans for 2ndFlrSF')\n",
    "plt.show() \"\"\"\n",
    "\n",
    "#3 groups is our optimal number of clusters for 2ndFlrSF\n",
    "\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(sflrsf)\n",
    "clusters_1 = kmeans.predict(sflrsf)\n",
    "df_sftflrsf = pd.DataFrame({'Value':train_final1['2ndFlrSF'],'Cluster':clusters_1})\n",
    "train_final1['2ndFlrSF Cluster'] = clusters_1\n",
    "train_final1.drop(columns=['2ndFlrSF'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GrLivArea - Put it into groups of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MSZoning - Only letting the first letter of the values (this way we will make RH, RL, RP and RM into one (Residential))\n",
    "LotShape - Transform data to keep only the first letter (R for Regular and I for Irregular)\n",
    "Neighborhood - Only keep first word and organize to be a clean data\n",
    "Create column (Overall) with the sum of OverallQual and OverallCond\n",
    "1stFlrSF and 2ndFlrSF - Put it into groups of data\n",
    "GrLivArea - Put it into groups of data\n",
    "Sum BsmtFullBath + BsmtHalfBath + FullBath + HalfBath\n",
    "WoodDeckSF - group\n",
    "OpenPorchSF - group\n",
    "EnclosedPorch - group\n",
    "PoolArea - group\n",
    "MiscVal - group\n",
    "SaleType - organize\n",
    "SaleCondition - organize\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
