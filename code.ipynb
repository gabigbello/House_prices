{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "#machine learning\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing train and test dataset\n",
    "test = pd.read_csv(\"test.csv\",sep=\",\")\n",
    "train = pd.read_csv(\"train.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#TRAIN DATASET\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train - description\n",
    "train.head(3) #initially we have a lot of null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train - shape\n",
    "train.shape #we have initially 1460 rows and 81 columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train - info\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Studying null values\n",
    "(train.isnull().sum()/train.shape[0]).sort_values(ascending=False).head(20) #finding % of null values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting all columns with more than 10% of null values\n",
    "remove = train.columns[(train.isnull().sum()/train.shape[0]) > 0.1]\n",
    "train = train.drop(remove,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking numeric columns\n",
    "numeric_columns = train.columns[train.dtypes != 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking categoric columns\n",
    "categoric_columns = train.columns[train.dtypes == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking and treating null values on numeric train base\n",
    "train_numeric = train.loc[:,numeric_columns]\n",
    "train_numeric.head()\n",
    "train_numeric.isnull().sum().sort_values(ascending=False) #Two columns with null values: GarageYrBlt and MasVnrArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GarageYrBlt\n",
    "top_garageyrblt = train_numeric.groupby(train_numeric['GarageYrBlt']).size().sort_values(ascending=False).head(5).tolist()\n",
    "#In order, we get: 2005.0,2006.0,2004.0,2003.0,2007.0. Will use these values to fill the null\n",
    "train_numeric['GarageYrBlt'].fillna(pd.Series(np.random.choice(top_garageyrblt,size=len(train_numeric.index))), inplace=True)\n",
    "#Checking if we still have null values\n",
    "train_numeric.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MasVnrArea\n",
    "top_masva = train_numeric.groupby(train_numeric['MasVnrArea']).size().sort_values(ascending=False).head(1)\n",
    "train_numeric['MasVnrArea'].fillna(top_masva, inplace=True)\n",
    "#Checking if we still have null values\n",
    "train_numeric.isnull().sum().sort_values(ascending=False) #No more null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking and treating null values on categoric train base\n",
    "train_categoric = train.loc[:,categoric_columns]\n",
    "train_categoric.head()\n",
    "train_categoric.isnull().sum().sort_values(ascending=False)\n",
    "'''\n",
    "Columns with null values:\n",
    "GarageCond       81\n",
    "GarageQual       81\n",
    "GarageFinish     81\n",
    "GarageType       81\n",
    "BsmtExposure     38\n",
    "BsmtFinType2     38\n",
    "BsmtCond         37\n",
    "BsmtFinType1     37\n",
    "BsmtQual         37\n",
    "Electrical        1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GarageCond\n",
    "garage_cond = train_categoric.groupby(train_categoric['GarageCond']).size().sort_values(ascending=False).head(5)\n",
    "#Since we have a huge difference between 'TA' and other values in this column, we will replace null values for 'TA'\n",
    "train_categoric['GarageCond'].fillna('TA',inplace=True)\n",
    "#Checking if we still have null values on GarageCond\n",
    "train_categoric.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GarageQual, GarageFinish, GarageType\n",
    "garage_qual = train_categoric.groupby(train_categoric['GarageQual']).size().sort_values(ascending=False).head(5) #same case as GarageCond\n",
    "garage_finish = train_categoric.groupby(train_categoric['GarageFinish']).size().sort_values(ascending=False).head(5)\n",
    "garage_type = train_categoric.groupby(train_categoric['GarageType']).size().sort_values(ascending=False).head(5)\n",
    "\n",
    "#Garage qual is the same case as GarageCond -> Fill with TA\n",
    "train_categoric['GarageQual'].fillna('TA',inplace=True)\n",
    "#For GarageFinish, we have not much difference between the data, so we will random fill the null values\n",
    "train_categoric['GarageFinish'].fillna(pd.Series(np.random.choice(garage_finish.tolist(),size=len(train_categoric.index))), inplace=True)\n",
    "#For GarageType, we have a huge difference between \"Attchd\" and other values, so we can fill the null values with this item\n",
    "train_categoric['GarageType'].fillna('Attchd',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BsmtExposure, BsmtFinType2, BsmtCond, BsmtQual, BsmtFinType1\n",
    "bsmt_exposure = train_categoric.groupby(train_categoric['BsmtExposure']).size().sort_values(ascending=False).head(5)\n",
    "#Replacing for No, since it's an outstanding class in the data\n",
    "train_categoric['BsmtExposure'].fillna('No',inplace=True)\n",
    "bsmt_fin2 = train_categoric.groupby(train_categoric['BsmtFinType2']).size().sort_values(ascending=False).head(5)\n",
    "#Replacing for Unf, since it's an outstanding class in the data\n",
    "train_categoric['BsmtFinType2'].fillna('Unf',inplace=True)\n",
    "bsmt_fin1 = train_categoric.groupby(train_categoric['BsmtFinType1']).size().sort_values(ascending=False).head(2)\n",
    "#Random fill with top 2 values (430 and 418)\n",
    "train_categoric['BsmtFinType1'].fillna(pd.Series(np.random.choice(bsmt_fin1.tolist(),size=len(train_categoric.index))), inplace=True)\n",
    "bsmt_cond = train_categoric.groupby(train_categoric['BsmtCond']).size().sort_values(ascending=False).head(5)\n",
    "#Filling null with TA, since it's the outstanding value\n",
    "train_categoric['BsmtCond'].fillna('TA',inplace=True)\n",
    "bsmt_qual = train_categoric.groupby(train_categoric['BsmtQual']).size().sort_values(ascending=False).head(5)\n",
    "#Random filling null with top 2 values (649 and 618)\n",
    "train_categoric['BsmtQual'].fillna(pd.Series(np.random.choice(bsmt_qual.tolist(),size=len(train_categoric.index))), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Electrical\n",
    "electrical = train_categoric.groupby(train_categoric['Electrical']).size().sort_values(ascending=False).head(5)\n",
    "#Fill with 'Sbrkr' which is the most outstanding value\n",
    "train_categoric['Electrical'].fillna('SBrkr',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting our final train_dataset by combining both numeric and categoric data\n",
    "train_dataset = pd.concat([train_numeric,train_categoric],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#TEST DATASET\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we will do the same thing we've done above to check for null values and understand our columns\n",
    "test.head(3)\n",
    "test.shape #1459 rows and 80 columns (no 'Sales price' column, which is what we want to predict)\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing all columns that have more than 10% of null values\n",
    "(test.isnull().sum()/test.shape[0]).sort_values(ascending=False).head(20)\n",
    "remove_test = test.columns[(test.isnull().sum()/test.shape[0]) > 0.1]\n",
    "test = test.drop(remove_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_tst = test.columns[test.dtypes != 'object']\n",
    "categoric_tst = test.columns[test.dtypes == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treating numeric values\n",
    "test_numeric = test.loc[:,numeric_tst]\n",
    "test_numeric.head(5)\n",
    "test_numeric.isnull().sum().sort_values(ascending=False).head(10) #10 columns with null values\n",
    "'''\n",
    "GarageYrBlt     78\n",
    "MasVnrArea      15\n",
    "BsmtHalfBath     2\n",
    "BsmtFullBath     2\n",
    "BsmtUnfSF        1\n",
    "GarageCars       1\n",
    "GarageArea       1\n",
    "BsmtFinSF1       1\n",
    "BsmtFinSF2       1\n",
    "TotalBsmtSF      1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping columns\n",
    "garage_yrblt = test_numeric.groupby(test_numeric['GarageYrBlt']).size().sort_values(ascending=False).head(5)\n",
    "masvnrarea = test_numeric.groupby(test_numeric['MasVnrArea']).size().sort_values(ascending=False).head(5)\n",
    "bsmthalfbath = test_numeric.groupby(test_numeric['BsmtHalfBath']).size().sort_values(ascending=False).head(5)\n",
    "bsmtfullbath = test_numeric.groupby(test_numeric['BsmtFullBath']).size().sort_values(ascending=False).head(5)\n",
    "bsmtunfsf = test_numeric.groupby(test_numeric['BsmtUnfSF']).size().sort_values(ascending=False).head(5)\n",
    "garagecars = test_numeric.groupby(test_numeric['GarageCars']).size().sort_values(ascending=False).head(5)\n",
    "garagearea = test_numeric.groupby(test_numeric['GarageArea']).size().sort_values(ascending=False).head(5)\n",
    "bsmtfinsf1 = test_numeric.groupby(test_numeric['BsmtFinSF1']).size().sort_values(ascending=False).head(5)\n",
    "bsmtfinsf2 = test_numeric.groupby(test_numeric['BsmtFinSF2']).size().sort_values(ascending=False).head(5)\n",
    "totalbsmtsf = test_numeric.groupby(test_numeric['TotalBsmtSF']).size().sort_values(ascending=False).head(2)\n",
    "\n",
    "#Garage_yrblt - Random fill with top 5 values\n",
    "test_numeric['GarageYrBlt'].fillna(pd.Series(np.random.choice(garage_yrblt.tolist(),size=len(test_numeric.index))), inplace=True)\n",
    "#MasVnrArea - Fill with 0.0\n",
    "test_numeric['MasVnrArea'].fillna('0.0',inplace=True)\n",
    "#BmstHalfBath - Fill with 0.0\n",
    "test_numeric['BsmtHalfBath'].fillna('0.0',inplace=True)\n",
    "#Bsmtfullbath - fill with 0.0\n",
    "test_numeric['BsmtFullBath'].fillna('0.0',inplace=True)\n",
    "#Bsmtunfsf - fill with 0.0\n",
    "test_numeric['BsmtUnfSF'].fillna('0.0',inplace=True)\n",
    "#Garagecars - fill with '2.0'\n",
    "test_numeric['GarageCars'].fillna('2.0',inplace=True)\n",
    "#GarageArea - randomic fill among top 5 values\n",
    "test_numeric['GarageArea'].fillna(pd.Series(np.random.choice(garagearea.tolist(),size=len(test_numeric.index))), inplace=True)\n",
    "#BsmtfinsF1 (Fill with '0.0') and BsmtfinsF2 (Fill with '0.0')\n",
    "test_numeric['BsmtFinSF1'].fillna('0.0',inplace=True)\n",
    "test_numeric['BsmtFinSF2'].fillna('0.0',inplace=True)\n",
    "#TotalBsmtSF - Randomic fill among top 2\n",
    "test_numeric['TotalBsmtSF'].fillna(pd.Series(np.random.choice(totalbsmtsf.tolist(),size=len(test_numeric.index))),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_categoric = test.loc[:,categoric_tst]\n",
    "test_categoric.head(5)\n",
    "test_categoric.isnull().sum().sort_values(ascending=False).head(16) #16 columns with null values\n",
    "'''\n",
    "GarageCond      78\n",
    "GarageQual      78\n",
    "GarageFinish    78\n",
    "GarageType      76\n",
    "BsmtCond        45\n",
    "BsmtExposure    44\n",
    "BsmtQual        44\n",
    "BsmtFinType1    42\n",
    "BsmtFinType2    42\n",
    "MSZoning         4\n",
    "Functional       2\n",
    "Utilities        2\n",
    "Exterior1st      1\n",
    "Exterior2nd      1\n",
    "SaleType         1\n",
    "KitchenQual      1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GarageCond      78\n",
    "tst_garagecond = test_categoric.groupby(test_categoric['GarageCond']).size().sort_values(ascending=False).head(5) \n",
    "test_categoric['GarageCond'].fillna('TA',inplace=True)\n",
    "#GarageQual      78\n",
    "tst_garagequal = test_categoric.groupby(test_categoric['GarageQual']).size().sort_values(ascending=False).head(5)\n",
    "test_categoric['GarageQual'].fillna('TA',inplace=True)\n",
    "#GarageFinish    78\n",
    "tst_garagefinish = test_categoric.groupby(test_categoric['GarageFinish']).size().sort_values(ascending=False).head(5)\n",
    "test_categoric['GarageFinish'].fillna('Unf',inplace=True)\n",
    "#GarageType      76\n",
    "tst_garagetype = test_categoric.groupby(test_categoric['GarageType']).size().sort_values(ascending=False).head(5)\n",
    "test_categoric['GarageType'].fillna('Attchd',inplace=True)\n",
    "#BsmtCond        45\n",
    "tst_bsmtcond = test_categoric.groupby(test_categoric['BsmtCond']).size().sort_values(ascending=False).head(5)\n",
    "test_categoric['BsmtCond'].fillna('TA',inplace=True)\n",
    "#BsmtExposure    44\n",
    "tst_bsmtexposure = test_categoric.groupby(test_categoric['BsmtExposure']).size().sort_values(ascending=False).head(5)\n",
    "test_categoric['BsmtExposure'].fillna('No',inplace=True)\n",
    "#BsmtQual        44\n",
    "tst_bsmtqual = test_categoric.groupby(test_categoric['BsmtQual']).size().sort_values(ascending=False).head(2)\n",
    "test_categoric['BsmtQual'].fillna(pd.Series(np.random.choice((tst_bsmtqual.tolist()),size=len(test_categoric.index))),inplace=True)\n",
    "#BsmtFinType1    42\n",
    "tst_bsmtfintype1 = test_categoric.groupby(test_categoric['BsmtFinType1']).size().sort_values(ascending=False).head(2)\n",
    "test_categoric['BsmtFinType1'].fillna(pd.Series(np.random.choice((tst_bsmtfintype1.tolist()),size=len(test_categoric.index))),inplace=True)\n",
    "#BsmtFinType2    42\n",
    "tst_bsmtfintype2 = test_categoric.groupby(test_categoric['BsmtFinType2']).size().sort_values(ascending=False).head(5)\n",
    "test_categoric['BsmtFinType2'].fillna('Unf',inplace=True)\n",
    "#MSZoning         4\n",
    "tst_mszoning = test_categoric.groupby(test_categoric['MSZoning']).size().sort_values(ascending=False).head(5)\n",
    "test_categoric['MSZoning'].fillna('RL',inplace=True)\n",
    "#Functional       2\n",
    "tst_functional = test_categoric.groupby(test_categoric['Functional']).size().sort_values(ascending=False).head(5)\n",
    "test_categoric['Functional'].fillna('Typ',inplace=True)\n",
    "#Utilities        2\n",
    "tst_utilities = test_categoric.groupby(test_categoric['Utilities']).size().sort_values(ascending=False).head(5) #Only AllPub\n",
    "test_categoric['Utilities'].fillna('AllPub',inplace=True)\n",
    "#Exterior1st      1\n",
    "tst_exterior1st = test_categoric.groupby(test_categoric['Exterior1st']).size().sort_values(ascending=False).head(5)\n",
    "test_categoric['Exterior1st'].fillna('VinylSd',inplace=True)\n",
    "#Exterior2nd      1\n",
    "tst_exterior2nd = test_categoric.groupby(test_categoric['Exterior2nd']).size().sort_values(ascending=False).head(5)\n",
    "test_categoric['Exterior2nd'].fillna('VinylSd',inplace=True)\n",
    "#SaleType         1\n",
    "tst_saletype = test_categoric.groupby(test_categoric['SaleType']).size().sort_values(ascending=False).head(5)\n",
    "test_categoric['SaleType'].fillna('WD',inplace=True)\n",
    "#KitchenQual      1\n",
    "tst_kitchenqual = test_categoric.groupby(test_categoric['KitchenQual']).size().sort_values(ascending=False).head(5)\n",
    "test_categoric['KitchenQual'].fillna('TA',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting our final test dataset with no null values\n",
    "test_dataset = pd.concat([test_numeric,test_categoric],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing train and test datasets\n",
    "columns_in_train_not_in_test = (set(train_dataset.columns)) - (set(test_dataset.columns))\n",
    "columns_in_test_not_in_train = (set(test_dataset.columns)) - (set(train_dataset.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#ORGANIZING DATASETS + CLEANING SOME COLUMNS\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we will clean our database by removing some columns that may not add important info to our study. \n",
    "\n",
    "#Some columns were chosen to be deleted initially from our database\n",
    "columns_to_remove = ['LandContour','LotConfig','YearRemodAdd','RoofStyle','Exterior2nd',\n",
    "                     'MasVnrArea','ExterCond','BsmtQual','BsmtExposure','BsmtFinSF1','BsmtFinType1','BsmtFinType2','BsmtFinSF2','BsmtUnfSF',\n",
    "                     'HeatingQC','Electrical','Functional','GarageYrBlt','GarageFinish','GarageCars','GarageCond','3SsnPorch',\n",
    "                     'ScreenPorch','MoSold','YrSold','LowQualFinSF','BedroomAbvGr','KitchenAbvGr','WoodDeckSF','OpenPorchSF', 'EnclosedPorch',\n",
    "                     'MiscVal','LandSlope','Condition1','Condition2','BldgType','Foundation','KitchenQual','GarageQual','SaleCondition']\n",
    "\n",
    "train_final1 = train_dataset.drop(columns_to_remove,axis=1)\n",
    "test_final1 = test_dataset.drop(columns_to_remove,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LotArea\n",
    "#Predicting clusters with train dataset\n",
    "lotarea_train = train_final1['LotArea'].values.reshape(-1,1)\n",
    "sse=[]\n",
    "for i in range(1,11):\n",
    "    kmeans = KMeans(n_clusters=i)\n",
    "    kmeans.fit(lotarea_train)\n",
    "    sse.append(kmeans.inertia_)\n",
    "#Ploting graph to understand the best clusters number\n",
    "\"\"\" plt.plot(range(1,11),sse,marker='x')\n",
    "plt.xlabel('Cluster numbers')\n",
    "plt.ylabel('Inertia sum')\n",
    "plt.title('Kmeans - Lot Area')\n",
    "plt.show() \"\"\"\n",
    "#Fitting our predict for train\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(lotarea_train)\n",
    "clusters = kmeans.predict(lotarea_train)\n",
    "train_final1['LotArea'] = clusters\n",
    "#Using the clusters to fit our test dataset\n",
    "lotarea_test = test_final1['LotArea'].values.reshape(-1,1)\n",
    "clusters_test = kmeans.predict(lotarea_test)\n",
    "test_final1['LotArea'] = clusters_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GrLivArea\n",
    "grlivarea_train = train_final1['GrLivArea'].values.reshape(-1,1)\n",
    "sse=[]\n",
    "for j in range(1,11):\n",
    "    kmeans_1 = KMeans(n_clusters=j)\n",
    "    kmeans_1.fit(grlivarea_train)\n",
    "    sse.append(kmeans_1.inertia_)\n",
    "\n",
    "\"\"\" plt.plot(range(1,11),sse,marker='x')\n",
    "plt.xlabel('Cluster numbers')\n",
    "plt.ylabel('Inertia sum')\n",
    "plt.title('Kmeans - GrLivArea')\n",
    "plt.show() \"\"\"\n",
    "\n",
    "kmeans_1 = KMeans(n_clusters=3)\n",
    "kmeans_1.fit(grlivarea_train)\n",
    "clusters_1 = kmeans_1.predict(grlivarea_train)\n",
    "train_final1['GrLivArea'] = clusters_1\n",
    "\n",
    "grlivarea_test = test_final1['GrLivArea'].values.reshape(-1,1)\n",
    "clusters_1_test = kmeans_1.predict(grlivarea_test)\n",
    "test_final1['GrLivArea'] = clusters_1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YearBuilt\n",
    "yrbuilt_train = train_final1['YearBuilt'].values.reshape(-1,1)\n",
    "sse=[]\n",
    "for k in range(1,11):\n",
    "    kmeans_2 = KMeans(n_clusters=k)\n",
    "    kmeans_2.fit(yrbuilt_train)\n",
    "    sse.append(kmeans_2.inertia_)\n",
    "\n",
    "\"\"\" plt.plot(range(1,11),sse,marker='x')\n",
    "plt.xlabel('Cluster numbers')\n",
    "plt.ylabel('Inertia sum')\n",
    "plt.title('Kmeans - YearBuilt')\n",
    "plt.show() \"\"\"\n",
    "\n",
    "kmeans_2 = KMeans(n_clusters=3)\n",
    "kmeans_2.fit(yrbuilt_train)\n",
    "clusters_2 = kmeans_2.predict(yrbuilt_train)\n",
    "train_final1['YearBuilt'] = clusters_2\n",
    "\n",
    "yrbuilt_test = test_final1['YearBuilt'].values.reshape(-1,1)\n",
    "clusters_2_test = kmeans_2.predict(yrbuilt_test)\n",
    "test_final1['YearBuilt'] = clusters_2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TotalBsmtSF\n",
    "totalbsmtsf_train = train_final1['TotalBsmtSF'].values.reshape(-1,1)\n",
    "sse=[]\n",
    "for l in range(1,11):\n",
    "    kmeans_3 = KMeans(n_clusters=l)\n",
    "    kmeans_3.fit(totalbsmtsf_train)\n",
    "    sse.append(kmeans_3.inertia_)\n",
    "\n",
    "\"\"\" plt.plot(range(1,11),sse,marker='x')\n",
    "plt.xlabel('Cluster numbers')\n",
    "plt.ylabel('Inertia sum')\n",
    "plt.title('Kmeans - TotalBsmtSF')\n",
    "plt.show() \"\"\"\n",
    "\n",
    "kmeans_3 = KMeans(n_clusters=3)\n",
    "kmeans_3.fit(totalbsmtsf_train)\n",
    "clusters_3 = kmeans_3.predict(totalbsmtsf_train)\n",
    "train_final1['TotalBsmtSF'] = clusters_3\n",
    "\n",
    "totalbsmtsf_test = test_final1['TotalBsmtSF'].values.reshape(-1,1)\n",
    "clusters_3_test = kmeans_3.predict(totalbsmtsf_test)\n",
    "test_final1['TotalBsmtSF'] = clusters_3_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1stFlrSF\n",
    "fstflrsf_train = train_final1['1stFlrSF'].values.reshape(-1,1)\n",
    "sse=[]\n",
    "for m in range(1,11):\n",
    "    kmeans_4 = KMeans(n_clusters=m)\n",
    "    kmeans_4.fit(fstflrsf_train)\n",
    "    sse.append(kmeans_4.inertia_)\n",
    "\n",
    "\"\"\" plt.plot(range(1,11),sse,marker='x')\n",
    "plt.xlabel('Cluster numbers')\n",
    "plt.ylabel('Inertia sum')\n",
    "plt.title('Kmeans - 1stFlrSF')\n",
    "plt.show() \"\"\"\n",
    "\n",
    "kmeans_4 = KMeans(n_clusters=3)\n",
    "kmeans_4.fit(fstflrsf_train)\n",
    "clusters_4 = kmeans_4.predict(fstflrsf_train)\n",
    "train_final1['1stFlrSF'] = clusters_4\n",
    "\n",
    "fstflrsf_test = test_final1['1stFlrSF'].values.reshape(-1,1)\n",
    "clusters_4_test = kmeans_4.predict(fstflrsf_test)\n",
    "test_final1['1stFlrSF'] = clusters_4_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2ndFlrSF\n",
    "sndflrsf_train = train_final1['2ndFlrSF'].values.reshape(-1,1)\n",
    "sse=[]\n",
    "for n in range(1,11):\n",
    "    kmeans_5 = KMeans(n_clusters=n)\n",
    "    kmeans_5.fit(sndflrsf_train)\n",
    "    sse.append(kmeans_5.inertia_)\n",
    "\n",
    "\"\"\" plt.plot(range(1,11),sse,marker='x')\n",
    "plt.xlabel('Cluster numbers')\n",
    "plt.ylabel('Inertia sum')\n",
    "plt.title('Kmeans - 2ndFlrSF')\n",
    "plt.show() \"\"\"\n",
    "\n",
    "kmeans_5 = KMeans(n_clusters=3)\n",
    "kmeans_5.fit(sndflrsf_train)\n",
    "clusters_5 = kmeans_5.predict(sndflrsf_train)\n",
    "train_final1['2ndFlrSF'] = clusters_5\n",
    "\n",
    "sndflrsf_test = test_final1['2ndFlrSF'].values.reshape(-1,1)\n",
    "clusters_5_test = kmeans_5.predict(sndflrsf_test)\n",
    "test_final1['2ndFlrSF'] = clusters_5_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GarageArea\n",
    "garagearea_train = train_final1['GarageArea'].values.reshape(-1,1)\n",
    "sse=[]\n",
    "for o in range(1,11):\n",
    "    kmeans_6 = KMeans(n_clusters=o)\n",
    "    kmeans_6.fit(garagearea_train)\n",
    "    sse.append(kmeans_6.inertia_)\n",
    "\n",
    "\"\"\" plt.plot(range(1,11),sse,marker='x')\n",
    "plt.xlabel('Cluster numbers')\n",
    "plt.ylabel('Inertia sum')\n",
    "plt.title('Kmeans - GarageArea')\n",
    "plt.show() \"\"\"\n",
    "\n",
    "kmeans_6 = KMeans(n_clusters=3)\n",
    "kmeans_6.fit(garagearea_train)\n",
    "clusters_6 = kmeans_6.predict(garagearea_train)\n",
    "train_final1['GarageArea'] = clusters_6\n",
    "\n",
    "garagearea_test = test_final1['GarageArea'].values.reshape(-1,1)\n",
    "clusters_6_test = kmeans_6.predict(garagearea_test)\n",
    "test_final1['GarageArea'] = clusters_6_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Other treatments columns:\n",
    "#Overall = OverallQual + OverallCond\n",
    "\n",
    "train_final1['Overall'] = train_final1['OverallCond'] + train_final1['OverallQual']\n",
    "test_final1['Overall'] = test_final1['OverallCond'] + test_final1['OverallQual']\n",
    "\n",
    "#Total Bath = BsmtFullBath + BsmtHalfBath + FullBath + HalfBath\n",
    "#print(test_final1[['BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath']].dtypes)\n",
    "#It was found that BsmtFullBath and BsmtHalfBath in test_final1 is type object, so we have to convert it to int to be able to sum\n",
    "train_final1['Total Bath'] = train_final1['BsmtFullBath'] + train_final1['BsmtHalfBath'] + train_final1['FullBath'] + train_final1['HalfBath']\n",
    "\n",
    "test_final1['BsmtFullBath'] = pd.to_numeric(test_final1['BsmtFullBath'], errors='coerce')\n",
    "test_final1['BsmtHalfBath'] = pd.to_numeric(test_final1['BsmtHalfBath'], errors='coerce')\n",
    "test_final1['BsmtFullBath'] = test_final1['BsmtFullBath'].fillna(0).astype(int)\n",
    "test_final1['BsmtHalfBath'] = test_final1['BsmtHalfBath'].fillna(0).astype(int)\n",
    "test_final1['Total Bath'] = test_final1['BsmtFullBath'] + test_final1['BsmtHalfBath'] + test_final1['FullBath'] + test_final1['HalfBath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fireplaces = 1 or 0\n",
    "fireplaces_train = train_final1.groupby(train_final1['Fireplaces']).size()\n",
    "fireplaces_train\n",
    "\"\"\"fireplaces_test = test_final1.groupby(test_final1['Fireplaces']).size()\n",
    "fireplaces_test \"\"\"\n",
    "\n",
    "#Replacing values for 0 (no fireplace) and 1 (there are fireplaces)\n",
    "sub = {0: 0, 1: 1, 2: 1, 3: 1, 4: 1}\n",
    "train_final1['Fireplaces'] = train_final1['Fireplaces'].map(sub)\n",
    "test_final1['Fireplaces'] = test_final1['Fireplaces'].map(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PoolArea = 1 or 0\n",
    "pool_train = train_final1.groupby(train_final1['PoolArea']).size()\n",
    "pool_test = test_final1.groupby(test_final1['PoolArea']).size()\n",
    "\n",
    "#Replacing values 0 (no pool), 1 (there is a pool) when value > 0\n",
    "train_final1['PoolArea'] = train_final1['PoolArea'].apply(lambda x: 0 if x == 0 else (1 if x >= 1 else x))\n",
    "test_final1['PoolArea'] = test_final1['PoolArea'].apply(lambda x: 0 if x == 0 else (1 if x >= 1 else x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSZoning = Keep only the first letter of each value (group residentials)\n",
    "train_final1['MSZoning'] = train_final1['MSZoning'].str[0]\n",
    "test_final1['MSZoning'] = test_final1['MSZoning'].str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Street = Paved = 1, Gravel = 0\n",
    "\n",
    "street_train = train_final1.groupby(train_final1['Street']).size()\n",
    "street_train\n",
    "\n",
    "street_test = test_final1.groupby(test_final1['Street']).size()\n",
    "street_test\n",
    "\n",
    "sub_street = {'Pave': 1, 'Grvl': 0}\n",
    "train_final1['Street'] = train_final1['Street'].map(sub_street)\n",
    "test_final1['Street'] = test_final1['Street'].map(sub_street)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LotShape = Regular, Irregular\n",
    "lotshape = train_final1.groupby(train_final1['LotShape']).size()\n",
    "lotshape_test = test_final1.groupby(test_final1['LotShape']).size()\n",
    "\n",
    "train_final1['LotShape'] = train_final1['LotShape'].str[0]\n",
    "test_final1['LotShape'] = test_final1['LotShape'].str[0]\n",
    "\n",
    "sub_lot = {'R': 1, 'I': 0}\n",
    "train_final1['LotShape'] = train_final1['LotShape'].map(sub_lot)\n",
    "test_final1['LotShape'] = test_final1['LotShape'].map(sub_lot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CentralAir = 1 or 0\n",
    "ca_train = train_final1.groupby(train_final1['CentralAir']).size()\n",
    "ca_test = test_final1.groupby(test_final1['CentralAir']).size()\n",
    "\n",
    "sub_ca = {'Y':1,'N':0}\n",
    "train_final1['CentralAir'] = train_final1['CentralAir'].map(sub_ca)\n",
    "test_final1['CentralAir'] = test_final1['CentralAir'].map(sub_ca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PavedDrive = 1 or 0\n",
    "paved_train = train_final1.groupby(train_final1['PavedDrive']).size()\n",
    "paved_test = test_final1.groupby(test_final1['PavedDrive']).size()\n",
    "\n",
    "#converting 'N' to 0 and 'P'/'Y' to 1\n",
    "sub_paved = {'N':0,'P':1,'Y':1}\n",
    "train_final1['PavedDrive'] = train_final1['PavedDrive'].map(sub_paved)\n",
    "test_final1['PavedDrive'] = test_final1['PavedDrive'].map(sub_paved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove_2 = ['OverallQual','OverallCond','BsmtHalfBath','BsmtFullBath','FullBath','HalfBath','Utilities','HouseStyle','RoofMatl','Heating'\n",
    "                       ,'Id','Exterior1st']\n",
    "\n",
    "train_final1 = train_final1.drop(columns=columns_to_remove_2,axis=1)\n",
    "test_final1 = test_final1.drop(columns=columns_to_remove_2,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding categoric columns\n",
    "train_final1_encoded = pd.get_dummies(train_final1)\n",
    "test_final1_encoded = pd.get_dummies(test_final1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_final1_encoded.isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving databases as csv to open and analyze the data\n",
    "train_final1_encoded.to_csv('train_final1.csv',index=False)\n",
    "test_final1_encoded.to_csv('test_final1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating x and y for our train model\n",
    "X = train_final1_encoded.drop('SalePrice',axis=1)\n",
    "y = train_final1_encoded.SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LinearRegression\n",
    "l_reg = LinearRegression().fit(X_train,y_train)\n",
    "y_lr = l_reg.predict(X_test)\n",
    "ma_lr = mean_absolute_error(y_test,y_lr)\n",
    "ms_lr = mean_squared_error(y_test,y_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tree\n",
    "tree_reg = tree.DecisionTreeRegressor(random_state=42).fit(X_train,y_train)\n",
    "y_tree = tree_reg.predict(X_test)\n",
    "ma_tree = mean_absolute_error(y_test,y_tree)\n",
    "ms_tree = mean_squared_error(y_test,y_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "knn = KNeighborsClassifier(n_neighbors = 2).fit(X_train,y_train)\n",
    "y_knn = knn.predict(X_test)\n",
    "ma_knn = mean_absolute_error(y_test,y_knn)\n",
    "ms_knn = mean_squared_error(y_test,y_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support Vector Machines\n",
    "svc = SVC().fit(X_train,y_train)\n",
    "y_svc = svc.predict(X_test)\n",
    "ma_svc = mean_absolute_error(y_test,y_svc)\n",
    "ms_svc = mean_squared_error(y_test,y_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gaussian Naive Bayes\n",
    "gaussian = GaussianNB().fit(X_train,y_train)\n",
    "y_gau = gaussian.predict(X_test)\n",
    "ma_gau = mean_absolute_error(y_test,y_gau)\n",
    "ms_gau = mean_squared_error(y_test,y_gau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perceptron\n",
    "perceptron = Perceptron().fit(X_train,y_train)\n",
    "y_per = perceptron.predict(X_test)\n",
    "ma_per = mean_absolute_error(y_test,y_per)\n",
    "ms_per = mean_squared_error(y_test,y_per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear SVC\n",
    "linear_svc = LinearSVC().fit(X_train,y_train)\n",
    "y_lsvc = linear_svc.predict(X_test)\n",
    "ma_lsvc = mean_absolute_error(y_test,y_lsvc)\n",
    "ms_lsvc = mean_squared_error(y_test,y_lsvc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stochastic Gradient Descent\n",
    "sgdc = SGDClassifier().fit(X_train,y_train)\n",
    "y_sgdc = sgdc.predict(X_test)\n",
    "ma_sgdc = mean_absolute_error(y_test,y_sgdc)\n",
    "ms_sgdc = mean_squared_error(y_test,y_sgdc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "r_forest = RandomForestClassifier(n_estimators=100).fit(X_train,y_train)\n",
    "y_rf = r_forest.predict(X_test)\n",
    "ma_rf = mean_absolute_error(y_test,y_rf)\n",
    "ms_rf = mean_squared_error(y_test,y_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Models Evaluation\n",
    "\n",
    "models_evaluation = pd.DataFrame(\n",
    "    {\n",
    "        'Model':['Linear Regression','Tree','KNN','SVC','Gaussian','Perceptron','Linear SVC','SGDC','Random Forest'],\n",
    "        'Abs Error': [ma_lr,ma_tree,ma_knn,ma_svc,ma_gau,ma_per,ma_lsvc,ma_sgdc,ma_rf],\n",
    "        'Squared Error': [ms_lr,ms_tree,ms_knn,ms_svc,ms_gau,ms_per,ms_lsvc,ms_sgdc,ms_rf]\n",
    "    }\n",
    ")\n",
    "\n",
    "#As the result will be evaluated by squared error (Kaggle description), we will sort by it\n",
    "models_evaluation.sort_values(by='Squared Error',ascending=True)\n",
    "\n",
    "print(models_evaluation) #Linear Regression is the most accurate model to predict this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Linear Regression to predict y_test\n",
    "y_pred = l_reg.predict(test_final1_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add saleprice column to test dataset\n",
    "test_final1['SalePrice'] = y_pred\n",
    "test_final1['Id'] = test['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting only Id and Sale Price from test_final1\n",
    "submission_file = test_final1[['Id','SalePrice']]\n",
    "submission_file.to_csv('submission_file.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
